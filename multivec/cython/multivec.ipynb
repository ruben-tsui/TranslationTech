{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multivec import BilingualModel, MonolingualModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BilingualModel(b'/mnt/c/NLP/collo/un16m.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_model = model.src_model\n",
    "zh_model = model.trg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assets',\n",
       " 'asset',\n",
       " 'Assets',\n",
       " 'Asset',\n",
       " 'property',\n",
       " 'Written-off',\n",
       " 'off-balance-sheet',\n",
       " 'proceeds',\n",
       " 'disposals',\n",
       " 'estate']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = '資產' # '獲益'\n",
    "enlist = model.src_closest(w.encode(), n=10)\n",
    "[e.decode() for (e, d) in enlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['敏鋭', '氣質', '好奇心', '社會意識', '認知', '特質', '敏感性', '道德觀念', '自我認識', '理解力', '敏感度', '激發起', '思想道德', '感性', '覺悟', '政治覺悟', '解構', '感知', '積極向上', '表達能力']\n"
     ]
    }
   ],
   "source": [
    "w = 'sensibility'\n",
    "zhlist = model.trg_closest(w.encode(), n=20)\n",
    "print([z.decode() for (z, d) in zhlist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(w1, w2, w3):\n",
    "    '''\n",
    "    Solves problems of the type:\n",
    "    w1 : w2 :: w3 : __\n",
    "    '''\n",
    "    closest_words = []\n",
    "    try:\n",
    "        w1v = model.src_model.word_vec(w1.encode())\n",
    "        w2v = model.src_model.word_vec(w2.encode())\n",
    "        w3v = model.trg_model.word_vec(w3.encode())\n",
    "        w4v = w3v + (w2v - w1v)\n",
    "        closest_words = [w.decode() for (w, d) in model.trg_model.closest_to_vec(w4v, n=15)]\n",
    "        closest_words = [w for w in closest_words if w not in [w1, w2, w3]]\n",
    "    except:\n",
    "        pass\n",
    "    if len(closest_words) == 0:\n",
    "        print(':-(')\n",
    "    else:\n",
    "        print('{} : {} :: {} : {}'.format(w1, w2, w3, closest_words[0]))\n",
    "        print(closest_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male : king :: 女性 : 婦女\n",
      "['婦女', '國王', '王后', '殿下', '女議員', '托亞', '婦女兒童', '貝絲梅', '婦女組織', '陛下', '聖職', '君主', '王國', '女王']\n"
     ]
    }
   ],
   "source": [
    "w1 = 'male'\n",
    "w2 = 'king'\n",
    "w3 = '女性'; \n",
    "analogy(w1, w2, w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy2(w1, w2, w3):\n",
    "    '''\n",
    "    Solves problems of the type:\n",
    "    w1 : w2 :: w3 : __\n",
    "    '''\n",
    "    closest_words = []\n",
    "    try:\n",
    "        w1v = model.trg_model.word_vec(w1.encode())\n",
    "        w2v = model.trg_model.word_vec(w2.encode())\n",
    "        w3v = model.src_model.word_vec(w3.encode())\n",
    "        w4v = w3v + (w2v - w1v)\n",
    "        closest_words = [w.decode() for (w, d) in model.src_model.closest_to_vec(w4v, n=15)]\n",
    "        closest_words = [w for w in closest_words if w not in [w1, w2, w3]]\n",
    "    except:\n",
    "        pass\n",
    "    if len(closest_words) == 0:\n",
    "        print(':-(')\n",
    "    else:\n",
    "        print('{} : {} :: {} : {}'.format(w1, w2, w3, closest_words[0]))\n",
    "        print(closest_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violations | abuses | violation | infringement | breaches | infringements | violated | grave | violating | VIOLATIONS | Violations | violate | flagrant | breach | acts | denial | violates | mistreatment | alleged | killings | atrocities | aggressions | blatant | allegations | arbitrary\n"
     ]
    }
   ],
   "source": [
    "# adj-modifier [JJ] (w2) + noun [NO] (w1)\n",
    "w1 = '疾病'\n",
    "w2 = '先天'\n",
    "w3 = 'disease'\n",
    "# adv-modifier (w2) + verb (w1)\n",
    "w1 = '氣候'\n",
    "w2 = '正常'\n",
    "w3 = 'phenomenon'\n",
    "\n",
    "w1 = '男'\n",
    "w2 = '國王'\n",
    "w3 = 'woman'\n",
    "\n",
    "# base=N, collocate=V\n",
    "w1 = '根基'# '根本'\n",
    "w2 = '鞏固' #'動搖'\n",
    "w3 = 'foundations'\n",
    "\n",
    "# base=N, collocate=V\n",
    "w1 = '秘密'# '根本'\n",
    "w2 = '發現' #'動搖'\n",
    "w3 = 'secrets'\n",
    "\n",
    "# base=N, collocate=V\n",
    "w1 = '人選'# '根本'\n",
    "w2 = '推薦' #'動搖'\n",
    "w3 = 'candidate'\n",
    "\n",
    "# verb [V] (w2) + direct object [DO] (w1)\n",
    "w1 = '犯罪'\n",
    "w2 = '打擊'\n",
    "w3 = 'crime'; \n",
    "\n",
    "# verb [V] (w2) + direct object [DO] (w1)\n",
    "w1 = '耕耘'\n",
    "w2 = '默默'\n",
    "w3 = 'work'; \n",
    "\n",
    "# verb [V] (w2) + direct object [DO] (w1)\n",
    "w1 = '名譽'\n",
    "w2 = '損害'\n",
    "w3 = 'reputation'; \n",
    "\n",
    "w1 = '隱私'\n",
    "w2 = '侵犯'\n",
    "w3 = 'privacy'; \n",
    "\n",
    "w1v = zh_model.word_vec(w1.encode())\n",
    "w2v = zh_model.word_vec(w2.encode())\n",
    "w3v = en_model.word_vec(w3.encode())\n",
    "w4v = w3v + (w2v - w1v)\n",
    "closest_words = [w.decode() for (w, d) in en_model.closest_to_vec(w4v, n=25)]\n",
    "print(' | '.join(closest_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'violations', 0.7513533234596252),\n",
       " (b'abuses', 0.6667124629020691),\n",
       " (b'violation', 0.6163552403450012),\n",
       " (b'infringement', 0.5891551375389099),\n",
       " (b'breaches', 0.5829546451568604),\n",
       " (b'infringements', 0.5725703239440918),\n",
       " (b'violated', 0.5636051893234253),\n",
       " (b'grave', 0.5541034936904907),\n",
       " (b'violating', 0.534368634223938),\n",
       " (b'VIOLATIONS', 0.5289359092712402),\n",
       " (b'Violations', 0.5284678936004639),\n",
       " (b'violate', 0.5158103704452515),\n",
       " (b'flagrant', 0.5001519918441772),\n",
       " (b'breach', 0.49738314747810364),\n",
       " (b'acts', 0.49735140800476074),\n",
       " (b'denial', 0.4968011975288391),\n",
       " (b'violates', 0.48997315764427185),\n",
       " (b'mistreatment', 0.48696815967559814),\n",
       " (b'alleged', 0.48206767439842224),\n",
       " (b'killings', 0.4805483818054199),\n",
       " (b'atrocities', 0.47416362166404724),\n",
       " (b'aggressions', 0.47053834795951843),\n",
       " (b'blatant', 0.4594906270503998),\n",
       " (b'allegations', 0.4562802314758301),\n",
       " (b'arbitrary', 0.45615482330322266)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " en_model.closest_to_vec(w4v, n=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collocate(w1, w2, w3):\n",
    "    '''\n",
    "    Given:\n",
    "        Chinese base w1 and Chinese collocate w2\n",
    "    Find:\n",
    "        candidates for collocate to English base w3\n",
    "    '''\n",
    "    closest_words = []\n",
    "    try:\n",
    "        w1v = model.trg_model.word_vec(w1.encode())\n",
    "        w2v = model.trg_model.word_vec(w2.encode())\n",
    "        w3v = model.src_model.word_vec(w3.encode())\n",
    "        w4v = w3v + (w2v - w1v)\n",
    "        closest_words = [w.decode() for (w, d) in model.src_model.closest_to_vec(w4v, n=15)]\n",
    "        closest_words = [w for w in closest_words if w not in [w1, w2, w3]]\n",
    "    except:\n",
    "        pass\n",
    "    if len(closest_words) == 0:\n",
    "        print(':-(')\n",
    "    else:\n",
    "        print('{} : {} :: {} : {}'.format(w1, w2, w3, closest_words[0]))\n",
    "        print(closest_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "因素 : 確定 :: factors : parameters\n",
      "['parameters', 'criteria', 'variables', 'determine', 'determining', 'scenarios', 'benchmarks', 'indicators', 'identifying', 'metrics', 'methodologies', 'baselines', 'identify', 'thresholds']\n"
     ]
    }
   ],
   "source": [
    "# adj-modifier [JJ] (w2) + noun [NO] (w1)\n",
    "w1 = '貧窮'\n",
    "w2 = ''\n",
    "w1 = '疾病'\n",
    "w2 = '治療'\n",
    "w3 = 'disease'\n",
    "w3 = 'poverty'\n",
    "\n",
    "\n",
    "# verb [V] (w2) + direct object [DO] (w1)\n",
    "w1 = '犯罪'\n",
    "w2 = '打擊'\n",
    "w3 = 'crime'; \n",
    "\n",
    "w1 = '因素'\n",
    "w2 = '確定'\n",
    "w3 = 'factors'\n",
    "\n",
    "collocate(w1, w2, w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collocate2(w1, w2, w3):\n",
    "    '''\n",
    "    Given:\n",
    "        Chinese base w1 and Chinese collocate w2\n",
    "    Find:\n",
    "        candidates for collocate to English base w3\n",
    "    '''\n",
    "    closest_words = []\n",
    "    try:\n",
    "        w1v = model.src_model.word_vec(w1.encode())\n",
    "        w2v = model.src_model.word_vec(w2.encode())\n",
    "        w3v = model.trg_model.word_vec(w3.encode())\n",
    "        w4v = w3v + (w2v - w1v)\n",
    "        closest_words = [w.decode() for (w, d) in model.trg_model.closest_to_vec(w4v, n=15)]\n",
    "        closest_words = [w for w in closest_words if w not in [w1, w2, w3]]\n",
    "    except:\n",
    "        pass\n",
    "    if len(closest_words) == 0:\n",
    "        print(':-(')\n",
    "    else:\n",
    "        print('{} : {} :: {} : {}'.format(w1, w2, w3, closest_words[0]))\n",
    "        print(closest_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "victim : abuse :: 受害者 : 虐待\n",
      "['虐待', '性虐待', '剝削', '性暴力', '濫用', '性侵犯', '暴力', '欺凌', '凌辱', '凌虐', '暴力行為', '虐待老人', '性', '家庭暴力']\n"
     ]
    }
   ],
   "source": [
    "w1 = 'victim'\n",
    "w2 = 'prominent'\n",
    "w3 = '犧牲者'\n",
    "\n",
    "w1 = 'victim'\n",
    "w2 = 'abuse'\n",
    "w3 = '受害者'\n",
    "\n",
    "collocate2(w1, w2, w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09458018600005236"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine as cos_dist\n",
    "cos_dist(model.src_model.word_vec('disease'.encode()), \n",
    "         model.trg_model.word_vec('疾病'.encode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":-(\n"
     ]
    }
   ],
   "source": [
    "w1 = '策略' \n",
    "w2 = '嚴厲'  \n",
    "w3 = 'policy'\n",
    "analogy(w1, w2, w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'analogy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9b9a0cb5c1ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'light'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mw3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'決定'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0manalogy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'analogy' is not defined"
     ]
    }
   ],
   "source": [
    "w3 = 'execution'\n",
    "w1 = 'rank' \n",
    "w2 = 'prioritize'  \n",
    "w1 = 'decision' \n",
    "w2 = 'light'  \n",
    "w3 = '決定'\n",
    "analogy(w1, w2, w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#en_model.sent_vec(b'Hong Kong') - en_model.word_vec(b'Hong') - en_model.word_vec(b'Kong')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def en2zh(txt, n=5):\n",
    "    retval = []\n",
    "    for (x,s) in model.trg_closest(txt.encode(), n):\n",
    "        retval.append(x.decode())\n",
    "    return retval\n",
    "\n",
    "def zh2en(txt, n=5):\n",
    "    retval = []\n",
    "    for (x,s) in model.src_closest(txt.encode(), n):\n",
    "        retval.append(x.decode())\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enSynonyms(txt, n=5):\n",
    "    retval = []\n",
    "    for (x,s) in model.src_model.closest(txt.encode(), n):\n",
    "        retval.append(x.decode())\n",
    "    return retval\n",
    "\n",
    "def zhSynonyms(txt, n=5):\n",
    "    retval = []\n",
    "    for (x,s) in model.trg_model.closest(txt.encode(), n):\n",
    "        retval.append(x.decode())\n",
    "    return retval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'appreciated | welcome | grateful | appreciates | commend | convey | thank | like | acknowledge | know | applaud | appreciative | attach | inform | thanks | thanked | hope | understand | hoped | express | compliment | trusted | expect | lend | offer'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = '''\n",
    "embryonic hazy predictably combined better vast shocking consequences results investigation\n",
    "approach bother approached gnawing troubling journey conversion dampen extinguish learn\n",
    "arrogant attention long-awaited knowledge seeker create beautiful scientific  uncovered\n",
    "intention purpose principal stories accounts describe provide development power exploring\n",
    "wilderness farming simplistic  discovery pioneers bunch recipient honour awarded connotation\n",
    "exuded pioneered front-runner understanding focus limelight obstacles still honored importance\n",
    "created talents proficiency complex acquainted inaugurated understanding ideas recognized\n",
    "praised difficult problematic recognized obscure coaching repurpose revive community top summit\n",
    "zenith pinnacle people appearance emergence subdue convincing specific fear apprehension affairs\n",
    "ordinary primeval citizens regulate constrain regulate operate development propose burgeoning proposal\n",
    "conjecture speculate theory amplified studies regular phenomena phenomenon natural relevant\n",
    "produce versatile utilitarian practical useful discovery conclude qualitative revolve debated\n",
    "atmosphere cordial environment reality demand baffled advocate championed untouched repulsive\n",
    "disturbing left improving enhance visually figure character specific perfect granted position\n",
    "self-serving selfish contribution amazing employ use textual  development propose introduce ideas\n",
    "recognize reflect flawless perfection decline dominant dominating stability simplicity already \n",
    "practices also aware varies create remarkable completely living residential order contraption \n",
    "invention apparatus ignore improvement enrolment cut dissected escape avoid evasion rising \n",
    "cover describe myth fantastic unsuccessful erroneous encompass cover harmony compatible \n",
    "unperturbed firmly uproot unchallenged far-reaching solid halt trouble contents valid complex \n",
    "intricate involved complicated system elevate humble tools mundane practical legend elevate \n",
    "orderly regularity condone accept integration short ephemeral contribution contribute \n",
    "strides splendour change legacy learn wholesale sweeping belief stationary remained adhered \n",
    "seafood difficult attempt widespread attacking power bold allegedly superior ethos atmosphere \n",
    "certainly aggressive active flatly just detained kept retained withheld appropriated \n",
    "expropriated forfeited pocket confiscated losses aggressive hooked indulging indulge \n",
    "intriguing amassed meticulously effective functioning treasure wealthy levied exploitation \n",
    "double flourishing foster uprising upheavals principal invasion autonomy future grew scale \n",
    "scattered joining large community marine maritime superior structure arrangement emerged \n",
    "alliance allied led dissatisfied upset angry dissatisfied angered destroyed obliterated \n",
    "devastated established However concede annihilated dissatisfaction carefree unrestrained \n",
    "unbridled hunting infiltrate interfere pretend benefits brash mistreated conflict \n",
    "rebellion spurned slight treated maltreated decisive definitive power \n",
    "occasion dispersed conflicts disagreement disharmony astute shrewd fatally dispersed \n",
    "scattered drifting drift forth between robust reasoning stationary immobile pulled eternal \n",
    "ephemeral detailed detail decay immortal mortal appropriate unchanging constant immutable \n",
    "smooth regulated sizable mortality purged thinking revived pinnacle summit illegality \n",
    "violation people bulge inflate layer abode terrestrial supreme allegations far-fetched \n",
    "bothered tame tamed centered predictable abundant regular movement motion birth structure \n",
    "sedge synthesize create fashioned connected amalgamated forcefully holes migration \n",
    "migrated settled immigrated beginnings replete integration consolidation integrate mingling \n",
    "astute randomly propagate labelled marked conflict  war prosper describe kick-starting \n",
    "revitalize  fruitless complete comprehensive celestial harbinger upheaval turbulent \n",
    "disastrous woe calamitous fateful scrutinize resurrect difficult estimate bumpy \n",
    "unhappy thinking understanding understand expensive gathered limited development \n",
    "explore exploration similar money costly experiment costly broken occasionally still \n",
    "instantly orderly realm mysterious operated reversed about-face adhered stable \n",
    "declining weakening precarious decline disarray learn disappeared foundation jump\n",
    "spread generous funded invasion dying waning rivalry declining stagnation changes \n",
    "integrated condemnation promotion spread shackles definite deemed wrong contention \n",
    "far-fetched assertion passionate stored freedom publishing ideas endowed proud revered \n",
    "beloved boasted mutual strategic unchallenged stranglehold backbone foundation \n",
    "pillars unshakable antiquated specially specifically orderliness reputation \n",
    "untouchable unassailable error theory concerned deliberately offended displeased \n",
    "conspired understand hideous terrify terrified shudder tort confusing Sadly resulting \n",
    "propose moderate significant description combination enlightened inspired poor \n",
    "affluent veiled enemies ineffective zone debate struggle spilled accessible attack \n",
    "misconduct iniquity offence issues censor review merit veracity implied student \n",
    "banned indeed finally unexpectedly experience appreciate \n",
    "'''\n",
    "words = words.strip().split()\n",
    "' | '.join(enSynonyms(words[-1], n=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'投機者 | 投機性 | 多國公司 | 掠奪性 | 爭先恐後 | 寡頭 | 擠走 | 投機 | 拉動 | 自然而然 | 拋售 | 有權有勢 | 接二連三 | 爭相 | 從眾 | 套利 | 壓低 | 出人意料 | 非正統 | 不擇手段 | 擠出 | 市場化 | 壟斷市場 | 投資商 | 貪得無厭'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = '''\n",
    "一窩蜂\n",
    "'''\n",
    "words = words.strip().split()\n",
    "' | '.join(zhSynonyms(words[-1], n=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'untapped | tap | tapped | harness | potentialities | unlocking | exhumation | unlock | exhumations | unexploited | Exhumation | tapping | talents | harnessing | exhume | excavation | potential | Tapping | exhumed | potentials | gravesites | harnessed | exhuming | high-potential | unleash | unexplored | discover | uncover | graves | Excavations | dig | Exhumations | creativity | discovering | creative'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = {0:'壓倒性', 1:'打擊', 2:'犯罪', 3:'報到', 4:'别有用心',\n",
    "         5:'紛亂',   6:'凌駕', 7:'穩健', 8:'款項', 9:'封建',\n",
    "         10:'基礎', 11:'變遷', 12:'動態', 13:'鞭策', 14:'督促',\n",
    "         15:'永恆', 16:'法則', 17:'亙古不變', 18:'穩健', 19:'維護',\n",
    "         20:'檢舉', 21:'天才', 22:'繼續', 23:'推廣', 24:'宣導',\n",
    "         25:'崗位', 26:'思維', 27:'幹部', 28:'持續', 29:'永續', 30:'焚燒',\n",
    "         31:'阻絕', 32:'斷絕', 33:'體現', 34:'用途', 35:'著作', 36:'針對',\n",
    "         37:'結合', 38:'一窩蜂', 39:'精神', 40:'投入', 41:'盡責', 42:'熱潮',\n",
    "         43:'宣導', 44:'深邃', 45:'得罪', 46:'佩服', 47:'停課', 48:'雛形',\n",
    "         49:'用盡', 50:'雛形', 51:'鉅細靡遺', 52:'倘佯', 53:'高昂', 54:'激情', 55:'範例',\n",
    "         56:'翻版', 57:'雷同', 58:'預料之中', 59:'攻訐', 60:'置身事外', 61:'位高權重', 62:'道理',\n",
    "         63:'合情合理', 64:'禍害', 65:'蹂躪', 66:'窒礙難行', 67:'趕出', 68:'趕出', 69:'低調', 70:'興高采烈',\n",
    "         71:'瘋狂', 72:'迫切', 73:'急不可耐', 74:'貫徹', 75:'例行公事', 76:'求助', 77:'重建', 78:'契機', \n",
    "         79:'源自', 80:'移植', 81:'嚴厲',\n",
    "         82:'釋懷', 83:'輪流', 84:'進退兩難', 85:'', 86:'', 87:'', 88:'', 89:'', 90:'', 91:'', 92:'', 93:'', 94:'', 95:'', 96:'', 97:'', 98:'', 99:''\n",
    "        }\n",
    "words = '''無力感 成效 不彰 毫無例外 破產 敗壞 名聲 死灰復燃 據聞 範疇 函授 原則上 融入 進退維谷 厲害 結合\n",
    "整合 初步 快速 考量 策略 排他性 合情合理 犧牲者 受害者 認同 同情 確認 無計可施 阻撓 騷擾 驅趕 震撼 曠野\n",
    "嘆為觀止 燦爛 結晶 定理 發展 得罪 養家 奧秘 縈繞 公然 犀利 僵持不下 朝氣 勃勃 然而 困擾 運作 作用力 從此\n",
    "課題 嚴肅 未婚 流離失所 轉換 實質 滋生 思想 澆熄 艱深 難懂 深奧 無措 不知所措 作風 桀驁不遜 桀傲不遜 桀敖不馴\n",
    "大家 瞭解 揭露 注意 結果 求知 接力 創建 凸顯 崁入 嵌入 初衷  觀點 真理 闡述 命題 發展 感受 愛恨 情仇 力量\n",
    "星象 探索 時序 整理 震撼 曠野 佩服 神奇 交互 看到 知名 開創 補強 補救 落差 接軌 審定 努力 複雜 認識\n",
    "棘手 下水 促成 標題 輔導 驗證 認證 鼎盛 險惡 叛變 叛離 帷幄 運籌 版圖 重疊 高山 安定 定居 部落 頂端 平民\n",
    "畏懼 籌碼 洪荒 人民 主張 眾人 規律 現象 發現 製作 規律 循環 反對者 實用 熱門 舒適 獨尊 明顯 合理性 \n",
    "留下 佐證 總結 嚴苛 貢獻 不遑多讓 傑出 色彩 重力 力矩 精彩  提出 喜愛 偏見 最少 自然 此外 另外 另一方面\n",
    "案例 名額 細膩 涵蓋 說成 描寫 結果 妄想 契合 瓦解 看似 完整 修正 思考 困擾 關係 嚴謹 內容 成立 說明 \n",
    "推翻 傳說 重新 建立 烏雲 密布 認同 統合 思想 短暫 華麗 貫穿 停留 主張 地位 啟示 乾脆 扣留 沉迷 變遷 \n",
    "主體 農產品 外侮 大規模 壯大 努力 加盟 大型 加工 前所未見 令人 失望 高階 榮景 豐收 消滅 重創 確立 \n",
    "盟主 幫主 血氣方剛 歸順 急行軍 雄厚 推理 涵蓋 聚集 天象 恆久 完美  破碎 層 大地 攸關 隨機 立論 相異 \n",
    "情仇 愛恨 透視 動能 動量 檢視 苦境 困境 本輪 神奇 可觀 重視 發現 教會學校 蕭條 萎縮 剽悍 傳播 傳授 \n",
    "束縛 必然性 必然 說明 反駁 觀察 細膩 風氣 上游 艱深 艱難 水車 彰顯 知名 知名度 鬆綁 研究員 根基 特別 \n",
    "立論 井然有序 發現 名譽 公開 耕耘 刻意 在意 打造 美中不足 證實 提出 描述 影射 愚蠢 果然 探索 發掘 \n",
    "'''\n",
    "words = words.strip().split()\n",
    "' | '.join(zh2en(words[-1], 35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distinguished\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'en2zh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c7e0ea546465>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0;34m' | '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men2zh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'en2zh' is not defined"
     ]
    }
   ],
   "source": [
    "words = {0:'shirk', 1:'credibility', 2:'legitimacy', 3:'cynical', 4:'permeate',\n",
    "         5:'tergiversate', 6:'eternal', 7:'crusade', 8:'splinter', 9:'whining',\n",
    "         10:'product', 11:'economic', 12:'aspect', 13:\"effect\", 14:\"context\", 15:\"outreach\",\n",
    "         16:'circulation', 17:'reflection', 18:'thaw', 19:'undermine', 20:'plaguing',\n",
    "         21:'streak', 22:'thought-provoking', 23:'encourage', 24:'dawn', 25:'prominence',\n",
    "         26:'thousands', 27:'leaders', 28:'introduced', 29:'measure', 30:'advocate', \n",
    "         31:'attempted', 32:'mimeograph', 33:'flurry', 34:'subtlety', 35:'aesthetics',\n",
    "         36:'centerpiece', 37:'aloof', 38:'influence', 39:'rhetorical', 40:'promise',\n",
    "         41:'articulate', 42:'painstakingly', 43:'bureaucratic', 44:'haze', 45:'afoul', \n",
    "         46:'restricted', 47:'inevitable', 48:'emotions', 49:'charged', 50:'addendum',\n",
    "         51:'opening', 52:'copy', 53:'abuse', 54:'resembling', 55:'circumstances', 56:'predictable',\n",
    "         57:'enslaved' , 58:'unsurprising', 59:'abuse', 60:'mock', 61:'reminiscent', 62:'victim', \n",
    "         63:'restate', 64:'provocative', 66:'irony', 67:'shrewd', 68:'properly', \n",
    "         69:'omnipotent', 70:'apparent', 71:'sense', 72:'considered',\n",
    "         73:'afflicted', 74:'hyperinflation', 75:'ossified', 76:'practical', 77:'promotion', \n",
    "         78:'initiative', 79:'symptom', 80:'stakes', 81:'discredit', \n",
    "         82:'pragmatism', 83:'discredited', 84:'credential', 85:'struggles', 86:'remove', \n",
    "         87:'supplementary', 88:'sector', 89:'oblivious', 90:'publicized',\n",
    "         91:'uncooperative', 92:'docile', 93:'reception', 94:'cheerful', 95:'eager', \n",
    "         96:'denounce', 97:'follow', 98:'initiative', 99:'afterthought', 100:'dutifully',\n",
    "         101:'executive', 102:'rationalise', 103:'petition', 104:'denied', 105:'casually',\n",
    "         106:'flourished', 107:'guidelines', 108:'material', 109:'significant', 110:'gains', \n",
    "         111:'arguments', 112:'escorts', 113:'obliterated', 114:'contrast', 115:'parity', \n",
    "         116:'unsettling', 117:'shifting', 118:'acknowledged', 119:'debt', 120:'permanently', \n",
    "         121:'details', 122:'plagued', 123:'stall', 124:'', 125:'', 126:'', 127:'', 128:'', 129:'', 130:'', 131:'', 132:'', 133:'', 134:'', 135:'', 136:'', 137:'', 138:'', 139:'', 140:'', 141:'', 142:'', 143:'', 144:'', 145:'', 146:'', 147:'', 148:'', 149:''\n",
    "        }\n",
    "words = '''set-up errant marshal dishonesty inefficiencies malaise problems broached\n",
    "permissible sentiment untouched languishing potent undercut blanket condemnation dismay heartland\n",
    "discredited lenient ruffle succinctly renewed cautious lull presumed manufactured\n",
    "range floatingcomplexities manifold defy aspects facets areas entail revamped institute form terse\n",
    "favored apprenticeship correspondence part-time syphoned emerging publicized ingress torture\n",
    "vexing mediator increasing claimed freewheel stalled consulted minimal representation electoral\n",
    "barely alarming slight resentment violence youthful uncontrollable wing impotent calculated\n",
    "bearings censured censored disconsolate aloud loudly insecurities blanket pamphlet zany\n",
    "exemplary spotting spot force hairdresser quietly combine preliminary better rapid timely survive\n",
    "mind shared propaganda slate undeterred ignorant publicized ingenious mockery valid invalidated\n",
    "indoctrination actions burgeoning inspirational inspire insensitivity incisive over-sympathy sympathetic\n",
    "nonsense espouse allege checked gesture managers grim cautious pruned manageable better-educated \n",
    "membership forge assertive hedge  qualifications caution endorsement stakes patronage \n",
    "dismissive reassuring rogue restructure perquisites contacts visionary service civil desperate \n",
    "service sensibility address deal tenor until surreptitious strains allegedly prey unabashedly\n",
    "materialistic approaches insatiable retrenchment compulsory bitterness graft associates \n",
    "disaffected youthful steadily mired  inextricably publicized delays evasions intransigence \n",
    "sullen hostility disillusioned exasperation exasperated receptive shunted paralyzed appeared\n",
    "boisterous potent endlessly engrossing muzzled pleas stymied impede loving fierce cajole\n",
    "restraint divided intransigence lobbied checked awash speakers faltering veteran anguished\n",
    "bedraggled overwhelmed treat mowed dutifully actions unspectacular activists summoned \n",
    "vowed idiosyncratic crackdown significance conclusion humorous amusing incessant  strains\n",
    "seriously harassed random advancement development forgive diffuse spread hostility \n",
    "covert overt corrosive intention reference allusion consolidated formidable consolidate\n",
    "views lapse oversight grudgingly acquiescence disruptive lumbering blunter threats\n",
    "definitive speculation collateral exacerbated militated permitted flagrant breathtaking\n",
    "inflexible scenarios remarkable prestige disputed contention deflected abrogation \n",
    "ventures borderland pronouncements accommodation edged rhetoric branded blatant\n",
    "looming protracted exploitation shadowing fined resentencing adulation booming \n",
    "sweatshops sprawling academics attempts anchored adequate spacious satisfactory sarcastic \n",
    "manifested clarity venture-capital emerging apocalypse defunct tortuous excoriated\n",
    "said satirist freshness irreverent stalwart acerbic approached bothering henceforth\n",
    "handiwork interchange reality elucidate reformulate regurgitation provide admirable\n",
    "farming topography complex obscure pinnacle primeval manifestations incontrovertible \n",
    "encapsulate rising refute splendour legacy joining redemption spurned immobile stationary \n",
    "mindset contention ardent legacy unearthed candidate drawbacks portfolio jarring \n",
    "mentality mindset surmise solid censure healthcare offer share community access attendee \n",
    "connection connections remiss demise esoteric twist futuristic niche tap banned precursor\n",
    "forerunner distinguished \n",
    "'''\n",
    "words = words.strip().split()\n",
    "w = words[-1]; print(w)\n",
    "' | '.join(en2zh(w, n=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"82:'', 83:'', 84:'', 85:'', 86:'', 87:'', 88:'', 89:'', 90:'', 91:'', 92:'', 93:'', 94:'', 95:'', 96:'', 97:'', 98:'', 99:''\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_entries = [f\"{x}:''\" for x in range(82,100)]\n",
    "', '.join(new_entries)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'提供援助 | 獲得 | 提供支援 | 提供數據 | 獲取 | 索取 | 提供方便 | 給予 | 提供情報 | 配備 | 發放 | 供給 | 掌握 | 傳遞 | 尋求 | 輸送 | 劃撥 | 索要 | 傳達 | 傳授 | 提供者 | 供應 | 求助 | 取用 | 派發'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = {0:'推廣', 1:'抱怨', 2:'作品', 3:'財務', 4:'憑藉', 5:'深邃', 6:'得罪', 7:'限閲', 8:'高昂', 9:'情緒', 10:'反映', \n",
    "         11:'翻版', 12:'情況', 13:'預知', 14:'侵害', 15:'侵害', 16:'不出所料', 17:'置身事外', 18:'表面', 19:'位高權重', 20:'道理', 21:'馴服', 22:'拖延'}\n",
    "words = '''\n",
    "馴服 拖延 營私舞弊 心態 面向 視角 面向 因素 多方 探討 努力 虐待 總括 厲害 初步 包圍 正當 嘲諷\n",
    "發芽 萌芽 蓬勃 犧牲者 犧牲者 同情 認同 消息 人數 刪減 呼籲 大家 別無選擇 應付  解決 破產 罷工\n",
    "無計可施  強而有力  引人入勝 請求 訴求 物色 走下坡 放緩 停滯 變化 控制 驅趕 騷擾 表面 嘆為 觀止\n",
    "原諒 局部性 蔓延 散佈 公然 公開 彙整 失算 失誤 設計 盡心 令人驚嘆 受挫 阻止 犀利 僵持不下 蓬勃\n",
    "夠用 足夠 萬劫 不復 問題 轉換 提供 \n",
    "'''\n",
    "words = words.strip().split()\n",
    "' | '.join(zhSynonyms(words[-1], 25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "    \\mathbb E e^{i t \\bar X_n }\n",
    "    & = \\mathbb E \\exp \\left\\{ i \\frac{t}{n} \\sum_{j=1}^n X_j \\right\\}\n",
    "    \\\\\n",
    "    & = \\mathbb E \\prod_{j=1}^n \\exp \\left\\{ i \\frac{t}{n} X_j \\right\\}\n",
    "    \\\\\n",
    "    & = \\prod_{j=1}^n \\mathbb E \\exp \\left\\{ i \\frac{t}{n} X_j \\right\\}\n",
    "    = [\\phi(t/n)]^n\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb R^{n}, x+y=z, \\mathbb P(A \\subset B)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8477, 120601)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('ℝ'), ord('𝜙')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
