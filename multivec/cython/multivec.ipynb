{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multivec import BilingualModel, MonolingualModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BilingualModel(b'/mnt/c/NLP/collo/un16m.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_model = model.src_model\n",
    "zh_model = model.trg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assets',\n",
       " 'asset',\n",
       " 'Assets',\n",
       " 'Asset',\n",
       " 'property',\n",
       " 'Written-off',\n",
       " 'off-balance-sheet',\n",
       " 'proceeds',\n",
       " 'disposals',\n",
       " 'estate']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 'è³‡ç”¢' # 'ç²ç›Š'\n",
    "enlist = model.src_closest(w.encode(), n=10)\n",
    "[e.decode() for (e, d) in enlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['æ•é‹­', 'æ°£è³ª', 'å¥½å¥‡å¿ƒ', 'ç¤¾æœƒæ„è­˜', 'èªçŸ¥', 'ç‰¹è³ª', 'æ•æ„Ÿæ€§', 'é“å¾·è§€å¿µ', 'è‡ªæˆ‘èªè­˜', 'ç†è§£åŠ›', 'æ•æ„Ÿåº¦', 'æ¿€ç™¼èµ·', 'æ€æƒ³é“å¾·', 'æ„Ÿæ€§', 'è¦ºæ‚Ÿ', 'æ”¿æ²»è¦ºæ‚Ÿ', 'è§£æ§‹', 'æ„ŸçŸ¥', 'ç©æ¥µå‘ä¸Š', 'è¡¨é”èƒ½åŠ›']\n"
     ]
    }
   ],
   "source": [
    "w = 'sensibility'\n",
    "zhlist = model.trg_closest(w.encode(), n=20)\n",
    "print([z.decode() for (z, d) in zhlist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(w1, w2, w3):\n",
    "    '''\n",
    "    Solves problems of the type:\n",
    "    w1 : w2 :: w3 : __\n",
    "    '''\n",
    "    closest_words = []\n",
    "    try:\n",
    "        w1v = model.src_model.word_vec(w1.encode())\n",
    "        w2v = model.src_model.word_vec(w2.encode())\n",
    "        w3v = model.trg_model.word_vec(w3.encode())\n",
    "        w4v = w3v + (w2v - w1v)\n",
    "        closest_words = [w.decode() for (w, d) in model.trg_model.closest_to_vec(w4v, n=15)]\n",
    "        closest_words = [w for w in closest_words if w not in [w1, w2, w3]]\n",
    "    except:\n",
    "        pass\n",
    "    if len(closest_words) == 0:\n",
    "        print(':-(')\n",
    "    else:\n",
    "        print('{} : {} :: {} : {}'.format(w1, w2, w3, closest_words[0]))\n",
    "        print(closest_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male : king :: å¥³æ€§ : å©¦å¥³\n",
      "['å©¦å¥³', 'åœ‹ç‹', 'ç‹å', 'æ®¿ä¸‹', 'å¥³è­°å“¡', 'æ‰˜äº', 'å©¦å¥³å…’ç«¥', 'è²çµ²æ¢…', 'å©¦å¥³çµ„ç¹”', 'é™›ä¸‹', 'è–è·', 'å›ä¸»', 'ç‹åœ‹', 'å¥³ç‹']\n"
     ]
    }
   ],
   "source": [
    "w1 = 'male'\n",
    "w2 = 'king'\n",
    "w3 = 'å¥³æ€§'; \n",
    "analogy(w1, w2, w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy2(w1, w2, w3):\n",
    "    '''\n",
    "    Solves problems of the type:\n",
    "    w1 : w2 :: w3 : __\n",
    "    '''\n",
    "    closest_words = []\n",
    "    try:\n",
    "        w1v = model.trg_model.word_vec(w1.encode())\n",
    "        w2v = model.trg_model.word_vec(w2.encode())\n",
    "        w3v = model.src_model.word_vec(w3.encode())\n",
    "        w4v = w3v + (w2v - w1v)\n",
    "        closest_words = [w.decode() for (w, d) in model.src_model.closest_to_vec(w4v, n=15)]\n",
    "        closest_words = [w for w in closest_words if w not in [w1, w2, w3]]\n",
    "    except:\n",
    "        pass\n",
    "    if len(closest_words) == 0:\n",
    "        print(':-(')\n",
    "    else:\n",
    "        print('{} : {} :: {} : {}'.format(w1, w2, w3, closest_words[0]))\n",
    "        print(closest_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violations | abuses | violation | infringement | breaches | infringements | violated | grave | violating | VIOLATIONS | Violations | violate | flagrant | breach | acts | denial | violates | mistreatment | alleged | killings | atrocities | aggressions | blatant | allegations | arbitrary\n"
     ]
    }
   ],
   "source": [
    "# adj-modifier [JJ] (w2) + noun [NO] (w1)\n",
    "w1 = 'ç–¾ç—…'\n",
    "w2 = 'å…ˆå¤©'\n",
    "w3 = 'disease'\n",
    "# adv-modifier (w2) + verb (w1)\n",
    "w1 = 'æ°£å€™'\n",
    "w2 = 'æ­£å¸¸'\n",
    "w3 = 'phenomenon'\n",
    "\n",
    "w1 = 'ç”·'\n",
    "w2 = 'åœ‹ç‹'\n",
    "w3 = 'woman'\n",
    "\n",
    "# base=N, collocate=V\n",
    "w1 = 'æ ¹åŸº'# 'æ ¹æœ¬'\n",
    "w2 = 'éå›º' #'å‹•æ–'\n",
    "w3 = 'foundations'\n",
    "\n",
    "# base=N, collocate=V\n",
    "w1 = 'ç§˜å¯†'# 'æ ¹æœ¬'\n",
    "w2 = 'ç™¼ç¾' #'å‹•æ–'\n",
    "w3 = 'secrets'\n",
    "\n",
    "# base=N, collocate=V\n",
    "w1 = 'äººé¸'# 'æ ¹æœ¬'\n",
    "w2 = 'æ¨è–¦' #'å‹•æ–'\n",
    "w3 = 'candidate'\n",
    "\n",
    "# verb [V] (w2) + direct object [DO] (w1)\n",
    "w1 = 'çŠ¯ç½ª'\n",
    "w2 = 'æ‰“æ“Š'\n",
    "w3 = 'crime'; \n",
    "\n",
    "# verb [V] (w2) + direct object [DO] (w1)\n",
    "w1 = 'è€•è€˜'\n",
    "w2 = 'é»˜é»˜'\n",
    "w3 = 'work'; \n",
    "\n",
    "# verb [V] (w2) + direct object [DO] (w1)\n",
    "w1 = 'åè­½'\n",
    "w2 = 'æå®³'\n",
    "w3 = 'reputation'; \n",
    "\n",
    "w1 = 'éš±ç§'\n",
    "w2 = 'ä¾µçŠ¯'\n",
    "w3 = 'privacy'; \n",
    "\n",
    "w1v = zh_model.word_vec(w1.encode())\n",
    "w2v = zh_model.word_vec(w2.encode())\n",
    "w3v = en_model.word_vec(w3.encode())\n",
    "w4v = w3v + (w2v - w1v)\n",
    "closest_words = [w.decode() for (w, d) in en_model.closest_to_vec(w4v, n=25)]\n",
    "print(' | '.join(closest_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'violations', 0.7513533234596252),\n",
       " (b'abuses', 0.6667124629020691),\n",
       " (b'violation', 0.6163552403450012),\n",
       " (b'infringement', 0.5891551375389099),\n",
       " (b'breaches', 0.5829546451568604),\n",
       " (b'infringements', 0.5725703239440918),\n",
       " (b'violated', 0.5636051893234253),\n",
       " (b'grave', 0.5541034936904907),\n",
       " (b'violating', 0.534368634223938),\n",
       " (b'VIOLATIONS', 0.5289359092712402),\n",
       " (b'Violations', 0.5284678936004639),\n",
       " (b'violate', 0.5158103704452515),\n",
       " (b'flagrant', 0.5001519918441772),\n",
       " (b'breach', 0.49738314747810364),\n",
       " (b'acts', 0.49735140800476074),\n",
       " (b'denial', 0.4968011975288391),\n",
       " (b'violates', 0.48997315764427185),\n",
       " (b'mistreatment', 0.48696815967559814),\n",
       " (b'alleged', 0.48206767439842224),\n",
       " (b'killings', 0.4805483818054199),\n",
       " (b'atrocities', 0.47416362166404724),\n",
       " (b'aggressions', 0.47053834795951843),\n",
       " (b'blatant', 0.4594906270503998),\n",
       " (b'allegations', 0.4562802314758301),\n",
       " (b'arbitrary', 0.45615482330322266)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " en_model.closest_to_vec(w4v, n=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collocate(w1, w2, w3):\n",
    "    '''\n",
    "    Given:\n",
    "        Chinese base w1 and Chinese collocate w2\n",
    "    Find:\n",
    "        candidates for collocate to English base w3\n",
    "    '''\n",
    "    closest_words = []\n",
    "    try:\n",
    "        w1v = model.trg_model.word_vec(w1.encode())\n",
    "        w2v = model.trg_model.word_vec(w2.encode())\n",
    "        w3v = model.src_model.word_vec(w3.encode())\n",
    "        w4v = w3v + (w2v - w1v)\n",
    "        closest_words = [w.decode() for (w, d) in model.src_model.closest_to_vec(w4v, n=15)]\n",
    "        closest_words = [w for w in closest_words if w not in [w1, w2, w3]]\n",
    "    except:\n",
    "        pass\n",
    "    if len(closest_words) == 0:\n",
    "        print(':-(')\n",
    "    else:\n",
    "        print('{} : {} :: {} : {}'.format(w1, w2, w3, closest_words[0]))\n",
    "        print(closest_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å› ç´  : ç¢ºå®š :: factors : parameters\n",
      "['parameters', 'criteria', 'variables', 'determine', 'determining', 'scenarios', 'benchmarks', 'indicators', 'identifying', 'metrics', 'methodologies', 'baselines', 'identify', 'thresholds']\n"
     ]
    }
   ],
   "source": [
    "# adj-modifier [JJ] (w2) + noun [NO] (w1)\n",
    "w1 = 'è²§çª®'\n",
    "w2 = ''\n",
    "w1 = 'ç–¾ç—…'\n",
    "w2 = 'æ²»ç™‚'\n",
    "w3 = 'disease'\n",
    "w3 = 'poverty'\n",
    "\n",
    "\n",
    "# verb [V] (w2) + direct object [DO] (w1)\n",
    "w1 = 'çŠ¯ç½ª'\n",
    "w2 = 'æ‰“æ“Š'\n",
    "w3 = 'crime'; \n",
    "\n",
    "w1 = 'å› ç´ '\n",
    "w2 = 'ç¢ºå®š'\n",
    "w3 = 'factors'\n",
    "\n",
    "collocate(w1, w2, w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collocate2(w1, w2, w3):\n",
    "    '''\n",
    "    Given:\n",
    "        Chinese base w1 and Chinese collocate w2\n",
    "    Find:\n",
    "        candidates for collocate to English base w3\n",
    "    '''\n",
    "    closest_words = []\n",
    "    try:\n",
    "        w1v = model.src_model.word_vec(w1.encode())\n",
    "        w2v = model.src_model.word_vec(w2.encode())\n",
    "        w3v = model.trg_model.word_vec(w3.encode())\n",
    "        w4v = w3v + (w2v - w1v)\n",
    "        closest_words = [w.decode() for (w, d) in model.trg_model.closest_to_vec(w4v, n=15)]\n",
    "        closest_words = [w for w in closest_words if w not in [w1, w2, w3]]\n",
    "    except:\n",
    "        pass\n",
    "    if len(closest_words) == 0:\n",
    "        print(':-(')\n",
    "    else:\n",
    "        print('{} : {} :: {} : {}'.format(w1, w2, w3, closest_words[0]))\n",
    "        print(closest_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "victim : abuse :: å—å®³è€… : è™å¾…\n",
      "['è™å¾…', 'æ€§è™å¾…', 'å‰å‰Š', 'æ€§æš´åŠ›', 'æ¿«ç”¨', 'æ€§ä¾µçŠ¯', 'æš´åŠ›', 'æ¬ºå‡Œ', 'å‡Œè¾±', 'å‡Œè™', 'æš´åŠ›è¡Œç‚º', 'è™å¾…è€äºº', 'æ€§', 'å®¶åº­æš´åŠ›']\n"
     ]
    }
   ],
   "source": [
    "w1 = 'victim'\n",
    "w2 = 'prominent'\n",
    "w3 = 'çŠ§ç‰²è€…'\n",
    "\n",
    "w1 = 'victim'\n",
    "w2 = 'abuse'\n",
    "w3 = 'å—å®³è€…'\n",
    "\n",
    "collocate2(w1, w2, w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09458018600005236"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine as cos_dist\n",
    "cos_dist(model.src_model.word_vec('disease'.encode()), \n",
    "         model.trg_model.word_vec('ç–¾ç—…'.encode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":-(\n"
     ]
    }
   ],
   "source": [
    "w1 = 'ç­–ç•¥' \n",
    "w2 = 'åš´å²'  \n",
    "w3 = 'policy'\n",
    "analogy(w1, w2, w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'analogy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9b9a0cb5c1ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'light'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mw3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'æ±ºå®š'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0manalogy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'analogy' is not defined"
     ]
    }
   ],
   "source": [
    "w3 = 'execution'\n",
    "w1 = 'rank' \n",
    "w2 = 'prioritize'  \n",
    "w1 = 'decision' \n",
    "w2 = 'light'  \n",
    "w3 = 'æ±ºå®š'\n",
    "analogy(w1, w2, w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#en_model.sent_vec(b'Hong Kong') - en_model.word_vec(b'Hong') - en_model.word_vec(b'Kong')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def en2zh(txt, n=5):\n",
    "    retval = []\n",
    "    for (x,s) in model.trg_closest(txt.encode(), n):\n",
    "        retval.append(x.decode())\n",
    "    return retval\n",
    "\n",
    "def zh2en(txt, n=5):\n",
    "    retval = []\n",
    "    for (x,s) in model.src_closest(txt.encode(), n):\n",
    "        retval.append(x.decode())\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enSynonyms(txt, n=5):\n",
    "    retval = []\n",
    "    for (x,s) in model.src_model.closest(txt.encode(), n):\n",
    "        retval.append(x.decode())\n",
    "    return retval\n",
    "\n",
    "def zhSynonyms(txt, n=5):\n",
    "    retval = []\n",
    "    for (x,s) in model.trg_model.closest(txt.encode(), n):\n",
    "        retval.append(x.decode())\n",
    "    return retval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'appreciated | welcome | grateful | appreciates | commend | convey | thank | like | acknowledge | know | applaud | appreciative | attach | inform | thanks | thanked | hope | understand | hoped | express | compliment | trusted | expect | lend | offer'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = '''\n",
    "embryonic hazy predictably combined better vast shocking consequences results investigation\n",
    "approach bother approached gnawing troubling journey conversion dampen extinguish learn\n",
    "arrogant attention long-awaited knowledge seeker create beautiful scientific  uncovered\n",
    "intention purpose principal stories accounts describe provide development power exploring\n",
    "wilderness farming simplistic  discovery pioneers bunch recipient honour awarded connotation\n",
    "exuded pioneered front-runner understanding focus limelight obstacles still honored importance\n",
    "created talents proficiency complex acquainted inaugurated understanding ideas recognized\n",
    "praised difficult problematic recognized obscure coaching repurpose revive community top summit\n",
    "zenith pinnacle people appearance emergence subdue convincing specific fear apprehension affairs\n",
    "ordinary primeval citizens regulate constrain regulate operate development propose burgeoning proposal\n",
    "conjecture speculate theory amplified studies regular phenomena phenomenon natural relevant\n",
    "produce versatile utilitarian practical useful discovery conclude qualitative revolve debated\n",
    "atmosphere cordial environment reality demand baffled advocate championed untouched repulsive\n",
    "disturbing left improving enhance visually figure character specific perfect granted position\n",
    "self-serving selfish contribution amazing employ use textual  development propose introduce ideas\n",
    "recognize reflect flawless perfection decline dominant dominating stability simplicity already \n",
    "practices also aware varies create remarkable completely living residential order contraption \n",
    "invention apparatus ignore improvement enrolment cut dissected escape avoid evasion rising \n",
    "cover describe myth fantastic unsuccessful erroneous encompass cover harmony compatible \n",
    "unperturbed firmly uproot unchallenged far-reaching solid halt trouble contents valid complex \n",
    "intricate involved complicated system elevate humble tools mundane practical legend elevate \n",
    "orderly regularity condone accept integration short ephemeral contribution contribute \n",
    "strides splendour change legacy learn wholesale sweeping belief stationary remained adhered \n",
    "seafood difficult attempt widespread attacking power bold allegedly superior ethos atmosphere \n",
    "certainly aggressive active flatly just detained kept retained withheld appropriated \n",
    "expropriated forfeited pocket confiscated losses aggressive hooked indulging indulge \n",
    "intriguing amassed meticulously effective functioning treasure wealthy levied exploitation \n",
    "double flourishing foster uprising upheavals principal invasion autonomy future grew scale \n",
    "scattered joining large community marine maritime superior structure arrangement emerged \n",
    "alliance allied led dissatisfied upset angry dissatisfied angered destroyed obliterated \n",
    "devastated established However concede annihilated dissatisfaction carefree unrestrained \n",
    "unbridled hunting infiltrate interfere pretend benefits brash mistreated conflict \n",
    "rebellion spurned slight treated maltreated decisive definitive power \n",
    "occasion dispersed conflicts disagreement disharmony astute shrewd fatally dispersed \n",
    "scattered drifting drift forth between robust reasoning stationary immobile pulled eternal \n",
    "ephemeral detailed detail decay immortal mortal appropriate unchanging constant immutable \n",
    "smooth regulated sizable mortality purged thinking revived pinnacle summit illegality \n",
    "violation people bulge inflate layer abode terrestrial supreme allegations far-fetched \n",
    "bothered tame tamed centered predictable abundant regular movement motion birth structure \n",
    "sedge synthesize create fashioned connected amalgamated forcefully holes migration \n",
    "migrated settled immigrated beginnings replete integration consolidation integrate mingling \n",
    "astute randomly propagate labelled marked conflict  war prosper describe kick-starting \n",
    "revitalize  fruitless complete comprehensive celestial harbinger upheaval turbulent \n",
    "disastrous woe calamitous fateful scrutinize resurrect difficult estimate bumpy \n",
    "unhappy thinking understanding understand expensive gathered limited development \n",
    "explore exploration similar money costly experiment costly broken occasionally still \n",
    "instantly orderly realm mysterious operated reversed about-face adhered stable \n",
    "declining weakening precarious decline disarray learn disappeared foundation jump\n",
    "spread generous funded invasion dying waning rivalry declining stagnation changes \n",
    "integrated condemnation promotion spread shackles definite deemed wrong contention \n",
    "far-fetched assertion passionate stored freedom publishing ideas endowed proud revered \n",
    "beloved boasted mutual strategic unchallenged stranglehold backbone foundation \n",
    "pillars unshakable antiquated specially specifically orderliness reputation \n",
    "untouchable unassailable error theory concerned deliberately offended displeased \n",
    "conspired understand hideous terrify terrified shudder tort confusing Sadly resulting \n",
    "propose moderate significant description combination enlightened inspired poor \n",
    "affluent veiled enemies ineffective zone debate struggle spilled accessible attack \n",
    "misconduct iniquity offence issues censor review merit veracity implied student \n",
    "banned indeed finally unexpectedly experience appreciate \n",
    "'''\n",
    "words = words.strip().split()\n",
    "' | '.join(enSynonyms(words[-1], n=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'æŠ•æ©Ÿè€… | æŠ•æ©Ÿæ€§ | å¤šåœ‹å…¬å¸ | æ å¥ªæ€§ | çˆ­å…ˆæå¾Œ | å¯¡é ­ | æ“ èµ° | æŠ•æ©Ÿ | æ‹‰å‹• | è‡ªç„¶è€Œç„¶ | æ‹‹å”® | æœ‰æ¬Šæœ‰å‹¢ | æ¥äºŒé€£ä¸‰ | çˆ­ç›¸ | å¾çœ¾ | å¥—åˆ© | å£“ä½ | å‡ºäººæ„æ–™ | éæ­£çµ± | ä¸æ“‡æ‰‹æ®µ | æ“ å‡º | å¸‚å ´åŒ– | å£Ÿæ–·å¸‚å ´ | æŠ•è³‡å•† | è²ªå¾—ç„¡å­'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = '''\n",
    "ä¸€çª©èœ‚\n",
    "'''\n",
    "words = words.strip().split()\n",
    "' | '.join(zhSynonyms(words[-1], n=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'untapped | tap | tapped | harness | potentialities | unlocking | exhumation | unlock | exhumations | unexploited | Exhumation | tapping | talents | harnessing | exhume | excavation | potential | Tapping | exhumed | potentials | gravesites | harnessed | exhuming | high-potential | unleash | unexplored | discover | uncover | graves | Excavations | dig | Exhumations | creativity | discovering | creative'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = {0:'å£“å€’æ€§', 1:'æ‰“æ“Š', 2:'çŠ¯ç½ª', 3:'å ±åˆ°', 4:'åˆ«æœ‰ç”¨å¿ƒ',\n",
    "         5:'ç´›äº‚',   6:'å‡Œé§•', 7:'ç©©å¥', 8:'æ¬¾é …', 9:'å°å»º',\n",
    "         10:'åŸºç¤', 11:'è®Šé·', 12:'å‹•æ…‹', 13:'é­ç­–', 14:'ç£ä¿ƒ',\n",
    "         15:'æ°¸æ†', 16:'æ³•å‰‡', 17:'äº™å¤ä¸è®Š', 18:'ç©©å¥', 19:'ç¶­è­·',\n",
    "         20:'æª¢èˆ‰', 21:'å¤©æ‰', 22:'ç¹¼çºŒ', 23:'æ¨å»£', 24:'å®£å°',\n",
    "         25:'å´—ä½', 26:'æ€ç¶­', 27:'å¹¹éƒ¨', 28:'æŒçºŒ', 29:'æ°¸çºŒ', 30:'ç„šç‡’',\n",
    "         31:'é˜»çµ•', 32:'æ–·çµ•', 33:'é«”ç¾', 34:'ç”¨é€”', 35:'è‘—ä½œ', 36:'é‡å°',\n",
    "         37:'çµåˆ', 38:'ä¸€çª©èœ‚', 39:'ç²¾ç¥', 40:'æŠ•å…¥', 41:'ç›¡è²¬', 42:'ç†±æ½®',\n",
    "         43:'å®£å°', 44:'æ·±é‚ƒ', 45:'å¾—ç½ª', 46:'ä½©æœ', 47:'åœèª²', 48:'é››å½¢',\n",
    "         49:'ç”¨ç›¡', 50:'é››å½¢', 51:'é‰…ç´°é¡éº', 52:'å€˜ä½¯', 53:'é«˜æ˜‚', 54:'æ¿€æƒ…', 55:'ç¯„ä¾‹',\n",
    "         56:'ç¿»ç‰ˆ', 57:'é›·åŒ', 58:'é æ–™ä¹‹ä¸­', 59:'æ”»è¨', 60:'ç½®èº«äº‹å¤–', 61:'ä½é«˜æ¬Šé‡', 62:'é“ç†',\n",
    "         63:'åˆæƒ…åˆç†', 64:'ç¦å®³', 65:'è¹‚èºª', 66:'çª’ç¤™é›£è¡Œ', 67:'è¶•å‡º', 68:'è¶•å‡º', 69:'ä½èª¿', 70:'èˆˆé«˜é‡‡çƒˆ',\n",
    "         71:'ç˜‹ç‹‚', 72:'è¿«åˆ‡', 73:'æ€¥ä¸å¯è€', 74:'è²«å¾¹', 75:'ä¾‹è¡Œå…¬äº‹', 76:'æ±‚åŠ©', 77:'é‡å»º', 78:'å¥‘æ©Ÿ', \n",
    "         79:'æºè‡ª', 80:'ç§»æ¤', 81:'åš´å²',\n",
    "         82:'é‡‹æ‡·', 83:'è¼ªæµ', 84:'é€²é€€å…©é›£', 85:'', 86:'', 87:'', 88:'', 89:'', 90:'', 91:'', 92:'', 93:'', 94:'', 95:'', 96:'', 97:'', 98:'', 99:''\n",
    "        }\n",
    "words = '''ç„¡åŠ›æ„Ÿ æˆæ•ˆ ä¸å½° æ¯«ç„¡ä¾‹å¤– ç ´ç”¢ æ•—å£ åè² æ­»ç°å¾©ç‡ƒ æ“šè ç¯„ç–‡ å‡½æˆ åŸå‰‡ä¸Š èå…¥ é€²é€€ç¶­è°· å²å®³ çµåˆ\n",
    "æ•´åˆ åˆæ­¥ å¿«é€Ÿ è€ƒé‡ ç­–ç•¥ æ’ä»–æ€§ åˆæƒ…åˆç† çŠ§ç‰²è€… å—å®³è€… èªåŒ åŒæƒ… ç¢ºèª ç„¡è¨ˆå¯æ–½ é˜»æ’“ é¨·æ“¾ é©…è¶• éœ‡æ’¼ æ› é‡\n",
    "å˜†ç‚ºè§€æ­¢ ç‡¦çˆ› çµæ™¶ å®šç† ç™¼å±• å¾—ç½ª é¤Šå®¶ å¥§ç§˜ ç¸ˆç¹ å…¬ç„¶ çŠ€åˆ© åƒµæŒä¸ä¸‹ æœæ°£ å‹ƒå‹ƒ ç„¶è€Œ å›°æ“¾ é‹ä½œ ä½œç”¨åŠ› å¾æ­¤\n",
    "èª²é¡Œ åš´è‚… æœªå©š æµé›¢å¤±æ‰€ è½‰æ› å¯¦è³ª æ»‹ç”Ÿ æ€æƒ³ æ¾†ç†„ è‰±æ·± é›£æ‡‚ æ·±å¥§ ç„¡æª ä¸çŸ¥æ‰€æª ä½œé¢¨ æ¡€é©ä¸éœ æ¡€å‚²ä¸éœ æ¡€æ•–ä¸é¦´\n",
    "å¤§å®¶ ç­è§£ æ­éœ² æ³¨æ„ çµæœ æ±‚çŸ¥ æ¥åŠ› å‰µå»º å‡¸é¡¯ å´å…¥ åµŒå…¥ åˆè¡·  è§€é» çœŸç† é—¡è¿° å‘½é¡Œ ç™¼å±• æ„Ÿå— æ„›æ¨ æƒ…ä»‡ åŠ›é‡\n",
    "æ˜Ÿè±¡ æ¢ç´¢ æ™‚åº æ•´ç† éœ‡æ’¼ æ› é‡ ä½©æœ ç¥å¥‡ äº¤äº’ çœ‹åˆ° çŸ¥å é–‹å‰µ è£œå¼· è£œæ•‘ è½å·® æ¥è»Œ å¯©å®š åŠªåŠ› è¤‡é›œ èªè­˜\n",
    "æ£˜æ‰‹ ä¸‹æ°´ ä¿ƒæˆ æ¨™é¡Œ è¼”å° é©—è­‰ èªè­‰ é¼ç›› éšªæƒ¡ å›è®Š å›é›¢ å¸·å¹„ é‹ç±Œ ç‰ˆåœ– é‡ç–Š é«˜å±± å®‰å®š å®šå±… éƒ¨è½ é ‚ç«¯ å¹³æ°‘\n",
    "ç•æ‡¼ ç±Œç¢¼ æ´ªè’ äººæ°‘ ä¸»å¼µ çœ¾äºº è¦å¾‹ ç¾è±¡ ç™¼ç¾ è£½ä½œ è¦å¾‹ å¾ªç’° åå°è€… å¯¦ç”¨ ç†±é–€ èˆ’é© ç¨å°Š æ˜é¡¯ åˆç†æ€§ \n",
    "ç•™ä¸‹ ä½è­‰ ç¸½çµ åš´è‹› è²¢ç» ä¸é‘å¤šè®“ å‚‘å‡º è‰²å½© é‡åŠ› åŠ›çŸ© ç²¾å½©  æå‡º å–œæ„› åè¦‹ æœ€å°‘ è‡ªç„¶ æ­¤å¤– å¦å¤– å¦ä¸€æ–¹é¢\n",
    "æ¡ˆä¾‹ åé¡ ç´°è†© æ¶µè“‹ èªªæˆ æå¯« çµæœ å¦„æƒ³ å¥‘åˆ ç“¦è§£ çœ‹ä¼¼ å®Œæ•´ ä¿®æ­£ æ€è€ƒ å›°æ“¾ é—œä¿‚ åš´è¬¹ å…§å®¹ æˆç«‹ èªªæ˜ \n",
    "æ¨ç¿» å‚³èªª é‡æ–° å»ºç«‹ çƒé›² å¯†å¸ƒ èªåŒ çµ±åˆ æ€æƒ³ çŸ­æš« è¯éº— è²«ç©¿ åœç•™ ä¸»å¼µ åœ°ä½ å•Ÿç¤º ä¹¾è„† æ‰£ç•™ æ²‰è¿· è®Šé· \n",
    "ä¸»é«” è¾²ç”¢å“ å¤–ä¾® å¤§è¦æ¨¡ å£¯å¤§ åŠªåŠ› åŠ ç›Ÿ å¤§å‹ åŠ å·¥ å‰æ‰€æœªè¦‹ ä»¤äºº å¤±æœ› é«˜éš æ¦®æ™¯ è±æ”¶ æ¶ˆæ»… é‡å‰µ ç¢ºç«‹ \n",
    "ç›Ÿä¸» å¹«ä¸» è¡€æ°£æ–¹å‰› æ­¸é † æ€¥è¡Œè» é›„åš æ¨ç† æ¶µè“‹ èšé›† å¤©è±¡ æ†ä¹… å®Œç¾  ç ´ç¢ å±¤ å¤§åœ° æ”¸é—œ éš¨æ©Ÿ ç«‹è«– ç›¸ç•° \n",
    "æƒ…ä»‡ æ„›æ¨ é€è¦– å‹•èƒ½ å‹•é‡ æª¢è¦– è‹¦å¢ƒ å›°å¢ƒ æœ¬è¼ª ç¥å¥‡ å¯è§€ é‡è¦– ç™¼ç¾ æ•™æœƒå­¸æ ¡ è•­æ¢ èç¸® å‰½æ‚ å‚³æ’­ å‚³æˆ \n",
    "æŸç¸› å¿…ç„¶æ€§ å¿…ç„¶ èªªæ˜ åé§ è§€å¯Ÿ ç´°è†© é¢¨æ°£ ä¸Šæ¸¸ è‰±æ·± è‰±é›£ æ°´è»Š å½°é¡¯ çŸ¥å çŸ¥ååº¦ é¬†ç¶ ç ”ç©¶å“¡ æ ¹åŸº ç‰¹åˆ¥ \n",
    "ç«‹è«– äº•ç„¶æœ‰åº ç™¼ç¾ åè­½ å…¬é–‹ è€•è€˜ åˆ»æ„ åœ¨æ„ æ‰“é€  ç¾ä¸­ä¸è¶³ è­‰å¯¦ æå‡º æè¿° å½±å°„ æ„šè ¢ æœç„¶ æ¢ç´¢ ç™¼æ˜ \n",
    "'''\n",
    "words = words.strip().split()\n",
    "' | '.join(zh2en(words[-1], 35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distinguished\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'en2zh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c7e0ea546465>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0;34m' | '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men2zh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'en2zh' is not defined"
     ]
    }
   ],
   "source": [
    "words = {0:'shirk', 1:'credibility', 2:'legitimacy', 3:'cynical', 4:'permeate',\n",
    "         5:'tergiversate', 6:'eternal', 7:'crusade', 8:'splinter', 9:'whining',\n",
    "         10:'product', 11:'economic', 12:'aspect', 13:\"effect\", 14:\"context\", 15:\"outreach\",\n",
    "         16:'circulation', 17:'reflection', 18:'thaw', 19:'undermine', 20:'plaguing',\n",
    "         21:'streak', 22:'thought-provoking', 23:'encourage', 24:'dawn', 25:'prominence',\n",
    "         26:'thousands', 27:'leaders', 28:'introduced', 29:'measure', 30:'advocate', \n",
    "         31:'attempted', 32:'mimeograph', 33:'flurry', 34:'subtlety', 35:'aesthetics',\n",
    "         36:'centerpiece', 37:'aloof', 38:'influence', 39:'rhetorical', 40:'promise',\n",
    "         41:'articulate', 42:'painstakingly', 43:'bureaucratic', 44:'haze', 45:'afoul', \n",
    "         46:'restricted', 47:'inevitable', 48:'emotions', 49:'charged', 50:'addendum',\n",
    "         51:'opening', 52:'copy', 53:'abuse', 54:'resembling', 55:'circumstances', 56:'predictable',\n",
    "         57:'enslaved' , 58:'unsurprising', 59:'abuse', 60:'mock', 61:'reminiscent', 62:'victim', \n",
    "         63:'restate', 64:'provocative', 66:'irony', 67:'shrewd', 68:'properly', \n",
    "         69:'omnipotent', 70:'apparent', 71:'sense', 72:'considered',\n",
    "         73:'afflicted', 74:'hyperinflation', 75:'ossified', 76:'practical', 77:'promotion', \n",
    "         78:'initiative', 79:'symptom', 80:'stakes', 81:'discredit', \n",
    "         82:'pragmatism', 83:'discredited', 84:'credential', 85:'struggles', 86:'remove', \n",
    "         87:'supplementary', 88:'sector', 89:'oblivious', 90:'publicized',\n",
    "         91:'uncooperative', 92:'docile', 93:'reception', 94:'cheerful', 95:'eager', \n",
    "         96:'denounce', 97:'follow', 98:'initiative', 99:'afterthought', 100:'dutifully',\n",
    "         101:'executive', 102:'rationalise', 103:'petition', 104:'denied', 105:'casually',\n",
    "         106:'flourished', 107:'guidelines', 108:'material', 109:'significant', 110:'gains', \n",
    "         111:'arguments', 112:'escorts', 113:'obliterated', 114:'contrast', 115:'parity', \n",
    "         116:'unsettling', 117:'shifting', 118:'acknowledged', 119:'debt', 120:'permanently', \n",
    "         121:'details', 122:'plagued', 123:'stall', 124:'', 125:'', 126:'', 127:'', 128:'', 129:'', 130:'', 131:'', 132:'', 133:'', 134:'', 135:'', 136:'', 137:'', 138:'', 139:'', 140:'', 141:'', 142:'', 143:'', 144:'', 145:'', 146:'', 147:'', 148:'', 149:''\n",
    "        }\n",
    "words = '''set-up errant marshal dishonesty inefficiencies malaise problems broached\n",
    "permissible sentiment untouched languishing potent undercut blanket condemnation dismay heartland\n",
    "discredited lenient ruffle succinctly renewed cautious lull presumed manufactured\n",
    "range floatingcomplexities manifold defy aspects facets areas entail revamped institute form terse\n",
    "favored apprenticeship correspondence part-time syphoned emerging publicized ingress torture\n",
    "vexing mediator increasing claimed freewheel stalled consulted minimal representation electoral\n",
    "barely alarming slight resentment violence youthful uncontrollable wing impotent calculated\n",
    "bearings censured censored disconsolate aloud loudly insecurities blanket pamphlet zany\n",
    "exemplary spotting spot force hairdresser quietly combine preliminary better rapid timely survive\n",
    "mind shared propaganda slate undeterred ignorant publicized ingenious mockery valid invalidated\n",
    "indoctrination actions burgeoning inspirational inspire insensitivity incisive over-sympathy sympathetic\n",
    "nonsense espouse allege checked gesture managers grim cautious pruned manageable better-educated \n",
    "membership forge assertive hedge  qualifications caution endorsement stakes patronage \n",
    "dismissive reassuring rogue restructure perquisites contacts visionary service civil desperate \n",
    "service sensibility address deal tenor until surreptitious strains allegedly prey unabashedly\n",
    "materialistic approaches insatiable retrenchment compulsory bitterness graft associates \n",
    "disaffected youthful steadily mired  inextricably publicized delays evasions intransigence \n",
    "sullen hostility disillusioned exasperation exasperated receptive shunted paralyzed appeared\n",
    "boisterous potent endlessly engrossing muzzled pleas stymied impede loving fierce cajole\n",
    "restraint divided intransigence lobbied checked awash speakers faltering veteran anguished\n",
    "bedraggled overwhelmed treat mowed dutifully actions unspectacular activists summoned \n",
    "vowed idiosyncratic crackdown significance conclusion humorous amusing incessant  strains\n",
    "seriously harassed random advancement development forgive diffuse spread hostility \n",
    "covert overt corrosive intention reference allusion consolidated formidable consolidate\n",
    "views lapse oversight grudgingly acquiescence disruptive lumbering blunter threats\n",
    "definitive speculation collateral exacerbated militated permitted flagrant breathtaking\n",
    "inflexible scenarios remarkable prestige disputed contention deflected abrogation \n",
    "ventures borderland pronouncements accommodation edged rhetoric branded blatant\n",
    "looming protracted exploitation shadowing fined resentencing adulation booming \n",
    "sweatshops sprawling academics attempts anchored adequate spacious satisfactory sarcastic \n",
    "manifested clarity venture-capital emerging apocalypse defunct tortuous excoriated\n",
    "said satirist freshness irreverent stalwart acerbic approached bothering henceforth\n",
    "handiwork interchange reality elucidate reformulate regurgitation provide admirable\n",
    "farming topography complex obscure pinnacle primeval manifestations incontrovertible \n",
    "encapsulate rising refute splendour legacy joining redemption spurned immobile stationary \n",
    "mindset contention ardent legacy unearthed candidate drawbacks portfolio jarring \n",
    "mentality mindset surmise solid censure healthcare offer share community access attendee \n",
    "connection connections remiss demise esoteric twist futuristic niche tap banned precursor\n",
    "forerunner distinguished \n",
    "'''\n",
    "words = words.strip().split()\n",
    "w = words[-1]; print(w)\n",
    "' | '.join(en2zh(w, n=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"82:'', 83:'', 84:'', 85:'', 86:'', 87:'', 88:'', 89:'', 90:'', 91:'', 92:'', 93:'', 94:'', 95:'', 96:'', 97:'', 98:'', 99:''\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_entries = [f\"{x}:''\" for x in range(82,100)]\n",
    "', '.join(new_entries)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'æä¾›æ´åŠ© | ç²å¾— | æä¾›æ”¯æ´ | æä¾›æ•¸æ“š | ç²å– | ç´¢å– | æä¾›æ–¹ä¾¿ | çµ¦äºˆ | æä¾›æƒ…å ± | é…å‚™ | ç™¼æ”¾ | ä¾›çµ¦ | æŒæ¡ | å‚³é | å°‹æ±‚ | è¼¸é€ | åŠƒæ’¥ | ç´¢è¦ | å‚³é” | å‚³æˆ | æä¾›è€… | ä¾›æ‡‰ | æ±‚åŠ© | å–ç”¨ | æ´¾ç™¼'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = {0:'æ¨å»£', 1:'æŠ±æ€¨', 2:'ä½œå“', 3:'è²¡å‹™', 4:'æ†‘è—‰', 5:'æ·±é‚ƒ', 6:'å¾—ç½ª', 7:'é™é–²', 8:'é«˜æ˜‚', 9:'æƒ…ç·’', 10:'åæ˜ ', \n",
    "         11:'ç¿»ç‰ˆ', 12:'æƒ…æ³', 13:'é çŸ¥', 14:'ä¾µå®³', 15:'ä¾µå®³', 16:'ä¸å‡ºæ‰€æ–™', 17:'ç½®èº«äº‹å¤–', 18:'è¡¨é¢', 19:'ä½é«˜æ¬Šé‡', 20:'é“ç†', 21:'é¦´æœ', 22:'æ‹–å»¶'}\n",
    "words = '''\n",
    "é¦´æœ æ‹–å»¶ ç‡Ÿç§èˆå¼Š å¿ƒæ…‹ é¢å‘ è¦–è§’ é¢å‘ å› ç´  å¤šæ–¹ æ¢è¨ åŠªåŠ› è™å¾… ç¸½æ‹¬ å²å®³ åˆæ­¥ åŒ…åœ æ­£ç•¶ å˜²è«·\n",
    "ç™¼èŠ½ èŒèŠ½ è“¬å‹ƒ çŠ§ç‰²è€… çŠ§ç‰²è€… åŒæƒ… èªåŒ æ¶ˆæ¯ äººæ•¸ åˆªæ¸› å‘¼ç±² å¤§å®¶ åˆ¥ç„¡é¸æ“‡ æ‡‰ä»˜  è§£æ±º ç ´ç”¢ ç½·å·¥\n",
    "ç„¡è¨ˆå¯æ–½  å¼·è€Œæœ‰åŠ›  å¼•äººå…¥å‹ è«‹æ±‚ è¨´æ±‚ ç‰©è‰² èµ°ä¸‹å¡ æ”¾ç·© åœæ»¯ è®ŠåŒ– æ§åˆ¶ é©…è¶• é¨·æ“¾ è¡¨é¢ å˜†ç‚º è§€æ­¢\n",
    "åŸè«’ å±€éƒ¨æ€§ è”“å»¶ æ•£ä½ˆ å…¬ç„¶ å…¬é–‹ å½™æ•´ å¤±ç®— å¤±èª¤ è¨­è¨ˆ ç›¡å¿ƒ ä»¤äººé©šå˜† å—æŒ« é˜»æ­¢ çŠ€åˆ© åƒµæŒä¸ä¸‹ è“¬å‹ƒ\n",
    "å¤ ç”¨ è¶³å¤  è¬åŠ« ä¸å¾© å•é¡Œ è½‰æ› æä¾› \n",
    "'''\n",
    "words = words.strip().split()\n",
    "' | '.join(zhSynonyms(words[-1], 25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "    \\mathbb E e^{i t \\bar X_n }\n",
    "    & = \\mathbb E \\exp \\left\\{ i \\frac{t}{n} \\sum_{j=1}^n X_j \\right\\}\n",
    "    \\\\\n",
    "    & = \\mathbb E \\prod_{j=1}^n \\exp \\left\\{ i \\frac{t}{n} X_j \\right\\}\n",
    "    \\\\\n",
    "    & = \\prod_{j=1}^n \\mathbb E \\exp \\left\\{ i \\frac{t}{n} X_j \\right\\}\n",
    "    = [\\phi(t/n)]^n\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb R^{n}, x+y=z, \\mathbb P(A \\subset B)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8477, 120601)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('â„'), ord('ğœ™')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
